{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Info\n\nThis Notebook was initially built off of [this Notebook](https://www.kaggle.com/code/ambrosm/amex-keras-quickstart-1-training) by AmbrosM\nI used this notebook to extract features constructed by CNN.","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install adabelief-tf --no-cache-dir \nfrom adabelief_tf import AdaBeliefOptimizer","metadata":{"execution":{"iopub.status.busy":"2022-08-18T14:04:31.802554Z","iopub.execute_input":"2022-08-18T14:04:31.803129Z","iopub.status.idle":"2022-08-18T14:04:43.276538Z","shell.execute_reply.started":"2022-08-18T14:04:31.803077Z","shell.execute_reply":"2022-08-18T14:04:43.275055Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport dill as pickle   \nfrom matplotlib import pyplot as plt\nimport random\nimport datetime\nimport math\nimport gc\nimport os\nimport warnings\nimport seaborn as sns\nimport itertools\nimport multiprocessing\nimport joblib\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nfrom matplotlib.ticker import MaxNLocator\nfrom colorama import Fore, Back, Style\nfrom tqdm import tqdm\nimport h5py\n\nfrom sklearn.model_selection import StratifiedKFold,KFold\nfrom sklearn.preprocessing import StandardScaler, QuantileTransformer, OneHotEncoder, PowerTransformer\nfrom sklearn.metrics import roc_curve, roc_auc_score, average_precision_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.utils import class_weight \nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport tensorflow_addons as tfa\nimport tensorflow as tf\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\ntf.config.threading.set_inter_op_parallelism_threads(4)\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model, load_model,model_from_json\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\nfrom tensorflow.keras.layers import Dense, Input, InputLayer, Add, Concatenate, Dropout, BatchNormalization, Conv1D, Reshape, Flatten, AveragePooling1D, MaxPool1D\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.losses import binary_crossentropy\nimport tensorflow.keras.backend as K","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-08-18T14:04:43.278672Z","iopub.execute_input":"2022-08-18T14:04:43.279258Z","iopub.status.idle":"2022-08-18T14:04:43.292909Z","shell.execute_reply.started":"2022-08-18T14:04:43.279194Z","shell.execute_reply":"2022-08-18T14:04:43.291769Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def amex_metric(y_true, y_pred):\n\n    labels     = np.transpose(np.array([y_true, y_pred]))\n    labels     = labels[labels[:, 1].argsort()[::-1]]\n    weights    = np.where(labels[:,0]==0, 20, 1)\n    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n\n    gini = [0,0]\n    for i in [1,0]:\n        labels         = np.transpose(np.array([y_true, y_pred]))\n        labels         = labels[labels[:, i].argsort()[::-1]]\n        weight         = np.where(labels[:,0]==0, 20, 1)\n        weight_random  = np.cumsum(weight / np.sum(weight))\n        total_pos      = np.sum(labels[:, 0] *  weight)\n        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n        lorentz        = cum_pos_found / total_pos\n        gini[i]        = np.sum((lorentz - weight_random) * weight)\n\n    return 0.5 * (gini[1]/gini[0] + top_four)\n    \nbest_score = 0\nclass MyCustomMetricCallback(tf.keras.callbacks.Callback):\n\n    def __init__(self, save_path, train=None, validation=None, best_score = 0):\n        super(MyCustomMetricCallback, self).__init__()\n        self.train = train\n        self.validation = validation\n        self.best_score = best_score\n        self.save_path =save_path\n        self.best_epoch = 0\n\n    def on_epoch_end(self, epoch, logs={}):\n        if self.train:\n#             logs['my_metric_train'] = float('inf')\n#             X_train, y_train = self.train[0], self.train[1]\n#             y_pred = self.model.predict(X_train)\n#             score = amex_metric_tensor(y_train, y_pred)\n#             logs['my_metric_train'] = np.round(score, 5)\n            pass\n\n        if self.validation:\n            X_valid, y_valid = self.validation[0], self.validation[1]\n            y_pred = self.model.predict(X_valid).reshape( (len(X_valid), )) \n            val_score = amex_metric(y_valid, y_pred)\n            logs['my_metric_val'] = val_score\n            if val_score>self.best_score:\n                self.best_score = val_score\n                self.best_epoch = epoch\n                self.model.save(f\"{self.save_path}.h5\")\n                print('best_val_score: ', self.best_score)\n            elif self.best_epoch==0:\n                if epoch-self.best_epoch > 40:\n                    self.model.stop_training = True\n            elif epoch-self.best_epoch > 12:\n                self.model.stop_training = True\n                \n            del X_valid, y_valid, y_pred, val_score\n            gc.collect()\n#Keras\n# def DiceBCELoss(targets, inputs, smooth=1e-6):  \n#     inputs = K.flatten(inputs)\n#     targets = K.flatten(targets)\n#     BCE =  binary_crossentropy(targets, inputs)\n#     intersection = K.sum(K.dot(targets, inputs))    \n#     dice_loss = 1 - (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n#     Dice_BCE = BCE + dice_loss\n    \n#     return Dice_BCE\n# ALPHA = 0.8\nALPHA= 5\nGAMMA = 2\ndef FocalLoss(targets, inputs, alpha=ALPHA, gamma=GAMMA):    \n    BCE = K.binary_crossentropy(targets, inputs)\n    BCE_EXP = K.exp(-BCE)\n    focal_loss = K.mean(alpha * K.pow((1-BCE_EXP), gamma) * BCE)\n    \n    return focal_loss","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-08-18T14:04:43.294487Z","iopub.execute_input":"2022-08-18T14:04:43.295339Z","iopub.status.idle":"2022-08-18T14:04:43.316383Z","shell.execute_reply.started":"2022-08-18T14:04:43.295296Z","shell.execute_reply":"2022-08-18T14:04:43.315373Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# The model\n\nEssentially the data I pass into the model is in the format of 15 features per category(P_2, B_3 etc.). So for example the first few features would be something like P_2_mean, P_2_max, P_2_last_mean_diff up to 15 features related to P_2 then there would be 15 features related to the next feature and so on. \n\nThe Conv1D processes all of the features related to that one feature individually, which leads to better model performance","metadata":{}},{"cell_type":"code","source":"def my_model(n_inputs):\n    \"\"\"Sequential neural network with a skip connection.\n    \n    Returns a compiled instance of tensorflow.keras.models.Model.\n    \"\"\"\n    activation = 'swish'\n    inputs = Input(shape=(n_inputs, ))\n    x = Reshape((n_inputs, 1))(inputs)\n    # 15 agg features per main feature, size = 15, step = 15.\n    x = Conv1D(24,15,strides=15, activation=activation)(x)\n    x = BatchNormalization()(x)\n    x = Conv1D(12,1, activation=activation)(x)\n    x = BatchNormalization()(x)\n    x = Conv1D(4,1, activation=activation)(x)\n    x = BatchNormalization()(x)\n    x = Flatten()(x)\n    x = Dropout(0.33)(x)\n    x = Dense(32, activation = activation)(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.1)(x)\n    x = Dense(16, activation = activation)(x)\n    outputs = Dense(1, activation='sigmoid')(x)\n    gc.collect()\n    return Model(inputs, outputs)\nmodel = my_model(190*15)\nmodel.summary()\ndel model","metadata":{"execution":{"iopub.status.busy":"2022-08-18T14:04:43.318597Z","iopub.execute_input":"2022-08-18T14:04:43.319152Z","iopub.status.idle":"2022-08-18T14:04:43.810636Z","shell.execute_reply.started":"2022-08-18T14:04:43.319102Z","shell.execute_reply":"2022-08-18T14:04:43.809508Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation\n\nWe use a standard cross-validation loop. In the loop, we train a model. We use a StratifiedKFold because the data is imbalanced.\n\neach fold takes approx ~1 hour to run","metadata":{}},{"cell_type":"code","source":"'''\nVERBOSE = 0\nCYCLES = 1\nEPOCHS = 400\nBATCH_SIZE = 2048\nFOLDS = 10\nSEED = 0\nCURRENT_FOLD = 9\n\ndef fit_model(seed, fold):\n    train = joblib.load('../input/amex-keras-dataset/train_agg_extra2_scaled.pkl').astype('float16')\n    #turn 2d feature array of shape (190, 15) into 1d array\n    train = np.array([i.flatten('C') for i in train])\n    gc.collect()\n    \n    target = pd.read_csv(f'../input/amex-default-prediction/train_labels.csv').target.astype('float32')\n    idx_tr, idx_va = list(StratifiedKFold(n_splits=FOLDS, shuffle= True, random_state= SEED).split(target,target))[fold]\n    X_va = train[idx_va]\n    X_tr = train[idx_tr]\n    y_tr, y_va = target[idx_tr], target[idx_va]\n    del train, target, idx_tr\n    gc.collect()\n    lr = ReduceLROnPlateau(monitor=\"val_loss\", \n                           factor=0.3, \n                           patience=5, \n                           mode = 'min', \n                           verbose=VERBOSE)\n    es = EarlyStopping(monitor=\"val_loss\",\n                       patience=7, \n                       min_delta=0.00001,\n                       verbose=VERBOSE,\n                       mode=\"min\", \n                       restore_best_weights=True)\n    best_score= 0\n    for seed1 in range(1):\n        print('seed: ',seed1)\n        np.random.seed(seed1)\n        random.seed(seed1)\n        tf.random.set_seed(seed1)\n        custom = MyCustomMetricCallback(save_path = f'model_fold{fold}_seed{seed}', validation=(X_va, y_va), best_score=best_score)\n                    \n        callbacks = [lr, \n                     es, \n                     tf.keras.callbacks.TerminateOnNaN(), \n                     custom,\n                     ]\n        model = my_model(X_tr.shape[1])\n        model.compile(optimizer=AdaBeliefOptimizer(learning_rate=0.02,\n                                                   weight_decay = 1e-5,\n                                                   epsilon = 1e-7,\n                                                   print_change_log = False,\n            ),\n            loss=FocalLoss,\n            )\n        gc.collect()\n        model.fit(X_tr, y_tr, \n                validation_data=(X_va, y_va),\n                epochs=EPOCHS,\n                verbose=VERBOSE,\n                batch_size=BATCH_SIZE,\n                shuffle=True,\n                callbacks=callbacks)\n        best_score = custom.best_score\n        gc.collect()\n        K.clear_session()\n     \n    return model\n\ndef fit_train_models(current_fold = 0):\n    print(f'KFOLD WITH SEED {SEED}:')\n    md=fit_model(SEED, current_fold)\n    gc.collect()\n    return md \n\nfinal_md=fit_train_models(current_fold = CURRENT_FOLD)\n# 0.2170, shape=(), dtype=float32) 0.7919 5\n'''","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-18T14:04:43.813731Z","iopub.execute_input":"2022-08-18T14:04:43.814745Z","iopub.status.idle":"2022-08-18T14:04:43.826570Z","shell.execute_reply.started":"2022-08-18T14:04:43.814699Z","shell.execute_reply":"2022-08-18T14:04:43.825494Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"VERBOSE = 0\nCYCLES = 1\nEPOCHS = 400\nBATCH_SIZE = 2048\nFOLDS = 10\nSEED = 0\nCURRENT_FOLD = 9\nfold=0\nseed=0\n\ntrain = joblib.load('../input/amex-keras-dataset/train_agg_extra2_scaled.pkl').astype('float16')\n#turn 2d feature array of shape (190, 15) into 1d array\ntrain = np.array([i.flatten('C') for i in train])\ngc.collect()\n\ntarget = pd.read_csv(f'../input/amex-default-prediction/train_labels.csv').target.astype('float32')\nidx_tr, idx_va = list(StratifiedKFold(n_splits=FOLDS, shuffle= True, random_state= SEED).split(target,target))[fold]\nX_va = train[idx_va]\nX_tr = train[idx_tr]\ny_tr, y_va = target[idx_tr], target[idx_va]\ndel train, target, idx_tr\ngc.collect()\nlr = ReduceLROnPlateau(monitor=\"val_loss\", \n                       factor=0.3, \n                       patience=5, \n                       mode = 'min', \n                       verbose=VERBOSE)\nes = EarlyStopping(monitor=\"val_loss\",\n                   patience=7, \n                   min_delta=0.00001,\n                   verbose=VERBOSE,\n                   mode=\"min\", \n                   restore_best_weights=True)\nbest_score= 0\nfor seed1 in range(1):\n    print('seed: ',seed1)\n    np.random.seed(seed1)\n    random.seed(seed1)\n    tf.random.set_seed(seed1)\n    custom = MyCustomMetricCallback(save_path = f'model_fold{fold}_seed{seed}', validation=(X_va, y_va), best_score=best_score)\n\n    callbacks = [lr, \n                 es, \n                 tf.keras.callbacks.TerminateOnNaN(), \n                 custom,\n                 ]\n    model = my_model(X_tr.shape[1])\n    model.compile(optimizer=AdaBeliefOptimizer(learning_rate=0.02,\n                                               weight_decay = 1e-5,\n                                               epsilon = 1e-7,\n                                               print_change_log = False,\n        ),\n        loss=FocalLoss,\n        )\n    gc.collect()\n    model.fit(X_tr, y_tr, \n            validation_data=(X_va, y_va),\n            epochs=EPOCHS,\n            verbose=VERBOSE,\n            batch_size=BATCH_SIZE,\n            shuffle=True,\n            callbacks=callbacks)\n    best_score = custom.best_score\n    gc.collect()\n    K.clear_session()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T14:04:43.828053Z","iopub.execute_input":"2022-08-18T14:04:43.828483Z","iopub.status.idle":"2022-08-18T14:40:01.434471Z","shell.execute_reply.started":"2022-08-18T14:04:43.828444Z","shell.execute_reply":"2022-08-18T14:40:01.433393Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tf.keras.models.save_model(model, \"./kt_model.hdf5\")\n\ntarget = pd.read_csv(f'../input/amex-default-prediction/train_labels.csv').target.astype('float32')\nidx_tr, idx_va = list(StratifiedKFold(n_splits=FOLDS, shuffle= True, random_state= SEED).split(target,target))[fold]","metadata":{"execution":{"iopub.status.busy":"2022-08-18T13:34:43.302615Z","iopub.execute_input":"2022-08-18T13:34:43.303181Z","iopub.status.idle":"2022-08-18T13:34:43.375816Z","shell.execute_reply.started":"2022-08-18T13:34:43.303130Z","shell.execute_reply":"2022-08-18T13:34:43.374774Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_tr=reduce_mem_usage(X_tr)\ntf.keras.models.load_model(\"./kt_model.hdf5\",custom_objects={\"optimizer\":AdaBeliefOptimizer})","metadata":{"execution":{"iopub.status.busy":"2022-08-18T13:33:01.325463Z","iopub.execute_input":"2022-08-18T13:33:01.326692Z","iopub.status.idle":"2022-08-18T13:33:01.378228Z","shell.execute_reply.started":"2022-08-18T13:33:01.326645Z","shell.execute_reply":"2022-08-18T13:33:01.376538Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"extractor = tf.keras.Model(inputs=model.inputs,\n                                outputs=model.layers[13].output)\nfeatures_train = extractor.predict(X_tr)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T14:56:07.290389Z","iopub.execute_input":"2022-08-18T14:56:07.290892Z","iopub.status.idle":"2022-08-18T14:56:07.302079Z","shell.execute_reply.started":"2022-08-18T14:56:07.290854Z","shell.execute_reply":"2022-08-18T14:56:07.301024Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train = joblib.load('../input/amex-keras-dataset/train_agg_extra2_scaled.pkl').astype('float16')","metadata":{"execution":{"iopub.status.busy":"2022-08-18T15:12:45.667481Z","iopub.execute_input":"2022-08-18T15:12:45.668069Z","iopub.status.idle":"2022-08-18T15:13:26.186560Z","shell.execute_reply.started":"2022-08-18T15:12:45.668023Z","shell.execute_reply":"2022-08-18T15:13:26.185353Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"CNN_ftr_tr=train['customer_ID']\ntemp=pd.DataFrame(features_train)\ntemp.to_csv(\"CNN_tr.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference\n\nBecause my dataset is too big, I need to run the inference after training the model on a separate run. \n\nWe also need to split the test data into multiple parts because of memory.\n\nThe following code is the result of running the above training 4 times with seeds 0,1,3,4","metadata":{}},{"cell_type":"code","source":"'''\n# # get oof predictions\ntrain = joblib.load('../input/amex-keras-dataset/train_agg_extra2_scaled.pkl').astype('float16')\ntrain = np.array([i.flatten('C') for i in train])\ngc.collect()\ntarget = pd.read_csv(f'../input/amex-default-prediction/train_labels.csv').target.astype('float32')\n\noof_predictions = np.zeros(len(train))\n\nfolds = [i for i in range(10)]\nseeds = [0]\n\ngc.collect()\nfor seed in tqdm(seeds):\n    oof_pred = np.zeros(len(train))\n    for fold, (idx_tr, idx_va) in enumerate(StratifiedKFold(n_splits=10, shuffle= True, random_state= seed).split(target,target)):\n        model = tf.keras.models.load_model(f'../input/amex-keras-models/model_fold{fold}_seed{seed}.h5',custom_objects={\"AdaBeliefOptimizer\":AdaBeliefOptimizer(learning_rate=0.02,weight_decay = 1e-5,epsilon = 1e-7,print_change_log = False,),                                                                                                            'FocalLoss': FocalLoss})\n        oof = model.predict(train[idx_va]).reshape((len(idx_va),) ) \n        print(amex_metric(target[idx_va], oof))\n        oof_pred[idx_va] += oof\n        gc.collect()\n        del model, oof\n        gc.collect()\n        K.clear_session()  \n    print(amex_metric(target, oof_pred))\n    oof_predictions += oof_pred/ len(seeds)\nprint(amex_metric(target, oof_predictions))\nsub = pd.read_csv('../input/amex-default-prediction/train_labels.csv').drop('target',axis=1)\nsub['prediction'] = oof_predictions\nsub.to_csv('keras-cnn_oof.csv')\ndel train,target,oof_predictions,sub\n'''","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-18T03:44:38.144927Z","iopub.status.idle":"2022-08-18T03:44:38.145836Z","shell.execute_reply.started":"2022-08-18T03:44:38.145606Z","shell.execute_reply":"2022-08-18T03:44:38.145628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # get submission predictions\n# test_pred=None\n# for pt in tqdm([1,2]):\n#     test = joblib.load(f'../input/amex-keras-dataset/test_agg_extra2_pt{pt}_scaled.pkl')\n#     test = np.array([i.flatten('C') for i in test])\n#     test_predictions = np.zeros(len(test))\n#     for seed,fold in tqdm(itertools.product(seeds,folds)):\n#         model = tf.keras.models.load_model(f'../input/amex-keras-models/model_fold{fold}_seed{seed}.h5',custom_objects={\"AdaBeliefOptimizer\":AdaBeliefOptimizer, 'FocalLoss': FocalLoss})\n#         def split(a, n):\n#             k, m = divmod(len(a), n)\n#             return [a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n)]\n#         split_ids = split(range(len(test)),2)\n#         for (j,ids) in enumerate(split_ids):\n#             test_predictions[ids] += model.predict(test[ids]).reshape((len(ids),) ) / len(folds) / len(seeds)\n#             gc.collect()\n#         del model, split_ids\n#         gc.collect()\n#         K.clear_session()\n#     if test_pred is None:\n#         test_pred = test_predictions\n#     else:\n#         test_pred = np.concatenate([test_pred,test_predictions])\n# sub = pd.read_csv('../input/amex-default-prediction/sample_submission.csv')\n# sub['prediction'] = test_pred\n# sub.to_csv('keras-cnn_sub.csv')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-18T03:44:38.147188Z","iopub.status.idle":"2022-08-18T03:44:38.147564Z","shell.execute_reply.started":"2022-08-18T03:44:38.147394Z","shell.execute_reply":"2022-08-18T03:44:38.147411Z"},"trusted":true},"execution_count":null,"outputs":[]}]}