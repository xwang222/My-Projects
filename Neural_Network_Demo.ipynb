{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1o34yZa5ZwsvbKJ64oFG_zgPdIaVshBle",
      "authorship_tag": "ABX9TyMSumebyI/ZXx8SDu7EbxNv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xwang222/My-Projects/blob/main/Neural_Network_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the dataframes are created for demonstration in Excel. They are not necessary for a neural network to work."
      ],
      "metadata": {
        "id": "_CuAPMLLgOEy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f2XQhwxfN95"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=pd.read_csv('/content/drive/MyDrive/ML Scratch/x_train.csv', header = None)  \n",
        "y_train_df=pd.read_csv('/content/drive/MyDrive/ML Scratch/y_train.csv', header = None)  "
      ],
      "metadata": {
        "id": "t_6fmepBfSKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes=[7, 5, 4, 3]\n",
        "input_layer=sizes[0]\n",
        "hidden_1=sizes[1]\n",
        "hidden_2=sizes[2]\n",
        "output_layer=sizes[3]\n",
        "\n",
        "params = {\n",
        "    'W1':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
        "    'W2':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
        "    'W3':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
        "}\n",
        "\n",
        "def sigmoid(x, derivative=False):\n",
        "        if derivative:\n",
        "            return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
        "        return 1/(1 + np.exp(-x))\n",
        "\n",
        "def softmax(x, derivative=False):\n",
        "    # Numerically stable with large exponentials\n",
        "    exps = np.exp(x - x.max())\n",
        "    if derivative:\n",
        "        return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
        "    return exps / np.sum(exps, axis=0)\n",
        "\n",
        "w1_all_df=pd.DataFrame()\n",
        "w2_all_df=pd.DataFrame()\n",
        "w3_all_df=pd.DataFrame()\n",
        "A1_all_df=pd.DataFrame()\n",
        "A2_all_df=pd.DataFrame()\n",
        "A3_all_df=pd.DataFrame()\n",
        "z1_all_df=pd.DataFrame()\n",
        "z2_all_df=pd.DataFrame()\n",
        "z3_all_df=pd.DataFrame()\n",
        "ch1_all_df=pd.DataFrame()\n",
        "ch2_all_df=pd.DataFrame()\n",
        "ch3_all_df=pd.DataFrame()\n",
        "w1_new_all_df=pd.DataFrame()\n",
        "w2_new_all_df=pd.DataFrame()\n",
        "w3_new_all_df=pd.DataFrame()\n",
        "err1_all_df=pd.DataFrame()\n",
        "err2_all_df=pd.DataFrame()\n",
        "err3_all_df=pd.DataFrame()"
      ],
      "metadata": {
        "id": "WBYy_ADlfU7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(1):\n",
        "  for i in range(len(x_train)):\n",
        "    x_dm=x_train.iloc[[i]]\n",
        "    y_dm=y_train_df.iloc[[i]]\n",
        "\n",
        "    # input layer activations becomes sample\n",
        "    params['A0'] = x_dm\n",
        "    A0_df=pd.DataFrame(params[\"A0\"])\n",
        "\n",
        "    # input layer to hidden layer 1\n",
        "    params['Z1'] = np.dot(params[\"W1\"], params['A0'].T)\n",
        "    params['A1'] = sigmoid(params['Z1'])\n",
        "\n",
        "    w1_df=pd.DataFrame(params[\"W1\"])\n",
        "    z1_df=pd.DataFrame(params[\"Z1\"])\n",
        "    A1_df=pd.DataFrame(params[\"A1\"])\n",
        "\n",
        "    w1_all_df=w1_all_df.append(w1_df, ignore_index=True)\n",
        "    z1_all_df=z1_all_df.append(z1_df, ignore_index=True)\n",
        "    A1_all_df=A1_all_df.append(A1_df, ignore_index=True)\n",
        "\n",
        "    params['Z2'] = np.dot(params[\"W2\"], params['A1'])\n",
        "    params['A2'] = sigmoid(params['Z2'])\n",
        "\n",
        "    w2_df=pd.DataFrame(params[\"W2\"])\n",
        "    z2_df=pd.DataFrame(params[\"Z2\"])\n",
        "    A2_df=pd.DataFrame(params[\"A2\"])\n",
        "\n",
        "    w2_all_df=w2_all_df.append(w2_df, ignore_index=True)\n",
        "    z2_all_df=z2_all_df.append(z2_df, ignore_index=True)\n",
        "    A2_all_df=A2_all_df.append(A2_df, ignore_index=True)\n",
        "\n",
        "    params['Z3'] = np.dot(params[\"W3\"], params['A2'])\n",
        "    params['A3'] = softmax(params['Z3'])\n",
        "\n",
        "    w3_df=pd.DataFrame(params[\"W3\"])\n",
        "    z3_df=pd.DataFrame(params[\"Z3\"])\n",
        "    A3_df=pd.DataFrame(params[\"A3\"])\n",
        "\n",
        "    w3_all_df=w3_all_df.append(w3_df, ignore_index=True)\n",
        "    z3_all_df=z3_all_df.append(z3_df, ignore_index=True)\n",
        "    A3_all_df=A3_all_df.append(A3_df, ignore_index=True)\n",
        "\n",
        "    change_w = {}\n",
        "    output = params['A3']\n",
        "    # Calculate W3 update\n",
        "    error = 2 * (output.T - y_dm) / output.shape[1] * softmax(params['Z3'], derivative=True).T\n",
        "    change_w['W3'] = np.outer(error.T, params['A2'])\n",
        "\n",
        "    ch3_df=pd.DataFrame(change_w[\"W3\"])\n",
        "    ch3_all_df=ch3_all_df.append(ch3_df, ignore_index=True)\n",
        "    err3_df = pd.DataFrame(error)\n",
        "    err3_all_df=err3_all_df.append(err3_df, ignore_index=True)\n",
        "\n",
        "    # Calculate W2 update\n",
        "    error = np.dot(error,params['W3']) * sigmoid(params['Z2'], derivative=True).T\n",
        "    change_w['W2'] = np.outer(error.T, params['A1'])\n",
        "\n",
        "    ch2_df=pd.DataFrame(change_w[\"W2\"])\n",
        "    ch2_all_df=ch2_all_df.append(ch2_df, ignore_index=True)\n",
        "    err2_df = pd.DataFrame(error)\n",
        "    err2_all_df=err2_all_df.append(err2_df, ignore_index=True)\n",
        "\n",
        "    # Calculate W1 update\n",
        "    error = np.dot(error,params['W2']) * sigmoid(params['Z1'], derivative=True).T\n",
        "    change_w['W1'] = np.outer(error.T, params['A0'])\n",
        "\n",
        "    ch1_df=pd.DataFrame(change_w[\"W1\"])\n",
        "    ch1_all_df=ch1_all_df.append(ch1_df, ignore_index=True)\n",
        "    err1_df = pd.DataFrame(error)\n",
        "    err1_all_df=err1_all_df.append(err1_df, ignore_index=True)    \n",
        "\n",
        "    l_rate = 1\n",
        "    for key, value in change_w.items():\n",
        "              params[key] -= l_rate * value\n",
        "\n",
        "    w1_df_new=pd.DataFrame(params[\"W1\"])\n",
        "    w2_df_new=pd.DataFrame(params[\"W2\"])\n",
        "    w3_df_new=pd.DataFrame(params[\"W3\"])\n",
        "\n",
        "    w1_new_all_df=w1_new_all_df.append(w1_df_new, ignore_index=True)\n",
        "    w2_new_all_df=w2_new_all_df.append(w2_df_new, ignore_index=True)\n",
        "    w3_new_all_df=w3_new_all_df.append(w3_df_new, ignore_index=True)"
      ],
      "metadata": {
        "id": "yITQ97EBfeFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1_all_df.to_csv('w1.csv')\n",
        "w2_all_df.to_csv('w2.csv')\n",
        "w3_all_df.to_csv('w3.csv')\n",
        "A1_all_df.to_csv('A1.csv')\n",
        "A2_all_df.to_csv('A2.csv')\n",
        "A3_all_df.to_csv('A3.csv')\n",
        "z1_all_df.to_csv('Z1.csv')\n",
        "z2_all_df.to_csv('Z2.csv')\n",
        "z3_all_df.to_csv('Z3.csv')\n",
        "ch1_all_df.to_csv('ch1.csv')\n",
        "ch2_all_df.to_csv('ch2.csv')\n",
        "ch3_all_df.to_csv('ch3.csv')\n",
        "w1_new_all_df.to_csv('w1_new.csv')\n",
        "w2_new_all_df.to_csv('w2_new.csv')\n",
        "w3_new_all_df.to_csv('w3_new.csv')\n",
        "err1_all_df.to_csv('err1_new.csv')\n",
        "err2_all_df.to_csv('err2_new.csv')\n",
        "err3_all_df.to_csv('err3_new.csv')"
      ],
      "metadata": {
        "id": "M-j7jCAnfhVM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}